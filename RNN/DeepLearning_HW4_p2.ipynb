{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_a3OXnSeV0z"
   },
   "source": [
    "\n",
    "<br>\n",
    "<font>\n",
    "<div dir=ltr align=center>\n",
    "<font color=0F5298 size=10>\n",
    "    Deep Learning - HW4 <br>\n",
    "<font color=2565AE size=5>\n",
    "    Electrical Engineering Department <br>\n",
    "    winter 2024<br>\n",
    "<font color=3C99D size=5>\n",
    "    Practical Assignment 2 <br>\n",
    "<font color=696880 size=4>\n",
    "    Armin Ghojehzadeh \n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔴 **Import Libs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vhlVJEkJeTsV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchtext\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import tqdm\n",
    "import torchmetrics as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DEzYlyeqTZqQ"
   },
   "outputs": [],
   "source": [
    "!python --version\n",
    "print(torch.__version__)\n",
    "print(torchtext.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6DWjGTq6T8Jg"
   },
   "outputs": [],
   "source": [
    "for lib in [np, torch, torchtext, tqdm]:\n",
    "  print(lib.__name__, '-->', lib.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwaY_YcgRayy"
   },
   "source": [
    "# 🔴 **Utils**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8yMS7bbmRayz"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PpKbTUEIRayz"
   },
   "outputs": [],
   "source": [
    "def num_trainable_params(model):\n",
    "  nums = sum(p.numel() for p in model.parameters() if p.requires_grad)/1e6\n",
    "  return nums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTql4Ftiunfr"
   },
   "source": [
    "# 🔴 **Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujIVtjsYvxOI"
   },
   "source": [
    "## 🟠 **Load the Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ek9DpCNCChzF"
   },
   "source": [
    "🔰 In this session you should load WikiText2 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ShYpXvVzVmP6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wCi-ofSLCzop"
   },
   "source": [
    "## 🟠 **Build vocabulary and save it**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L02PHFuyNRb3"
   },
   "source": [
    "🔰 In this section we need to:\n",
    "\n",
    "*   Define a tokenizer using `basic_english`\n",
    "*   Tokenize the dataset and collect tokens\n",
    "*   Build the vocabulary using `build_vocab_from_iterator`\n",
    "*   Manually insert special tokens and set the default index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dlJ6Q6xCVuf0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B29jrEvwRqXA"
   },
   "source": [
    "## 🟠 EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHtoYxEPd3bL"
   },
   "source": [
    "### 🟡 Let's explore the WikiText2 dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A3rnR739GbYb"
   },
   "source": [
    "### 🟡 Calculate basic statistics such as the number of documents, total words, average document length, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jHVKeKwk2WaG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4HyLPqcsF43"
   },
   "source": [
    "### 🟡 Analyze the most common and least common words in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBnEjagdTN8n"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfBasjQCE_aI"
   },
   "source": [
    "### 🟡  Please proceed with further exploration of the dataset. what do you suggest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yR8uQsv4E_aJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idRexFij4wgN"
   },
   "source": [
    "## 🟠 Transform the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VjvBOtvHu2v"
   },
   "source": [
    "🛑 Make sure to perform the transformations on train, validation and test datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApisIcGeGSsJ"
   },
   "source": [
    "🔰 Reshape the dataset into an `N x B x L` or `M x L` format, where `N` represents the number of batches, `B` is the batch size, `L` is the length of a sample within each batch, and `M` is equal to `N x B`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ocxM8YdsWH-1"
   },
   "outputs": [],
   "source": [
    "def data_process(raw_text_iter, batch_size, seq_len):\n",
    "\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4GndG2B0WPIb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PgLgP04P4-aX"
   },
   "source": [
    "## 🟠 Custom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkxH_IR2PBNq"
   },
   "source": [
    "🔰 Write a custom dataset class for LanguageModelDataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1cjpSkrtexap"
   },
   "outputs": [],
   "source": [
    "class LanguageModelDataset(Dataset):\n",
    "\n",
    "  def __init__(self, inputs, targets):\n",
    "    pass\n",
    "\n",
    "  def __len__(self):\n",
    "    pass\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o0qUkL0CfQmr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCQjacybOfqV"
   },
   "source": [
    "## 🟠 Define a dataloader if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HqKMEyFNS-1a"
   },
   "source": [
    "🔰 Write dataloaders for the training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMCJ3UMD0U_f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ttl0AK3Hvyh"
   },
   "source": [
    "# 🔴 **Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06p-oBowTf-R"
   },
   "source": [
    "🔰 Use the following template to create a custom model.\n",
    "\n",
    "Your model should consist of three parts:\n",
    "\n",
    "*   an embedding layer\n",
    "*   an LSTM layer\n",
    "*   a fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ISnnHE0BMVqp"
   },
   "outputs": [],
   "source": [
    "class LanguageModel(nn.Module):\n",
    "\n",
    "  def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, dropout_rate):\n",
    "    pass\n",
    "\n",
    "  def forward(self, src):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2MgBVzorb9oQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24qT-sgUO2-d"
   },
   "source": [
    "# 🔴 **Config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ma28M5Z36gsq"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwYDJKjuduUT"
   },
   "source": [
    "🔰 Define the optimizer, loss function, metrics and other necessary parameters in this section, and ensure the model is sent to the appropriate device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ubk3xKaIG6i"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0QNbC0YPCKZ"
   },
   "source": [
    "# 🔴 **Train ➰**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yS6EF4HUhi5e"
   },
   "source": [
    "🔰 This is the template for train function, change it if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WniOAgk0QyRI"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, loss_fn, optimizer, metric, epoch=None):\n",
    "  model.train()\n",
    "  loss_train = AverageMeter()\n",
    "  metric.reset()\n",
    "\n",
    "  with tqdm.tqdm(train_loader, unit='batch') as tepoch:\n",
    "    for inputs, targets in tepoch:\n",
    "      if epoch:\n",
    "        tepoch.set_description(f'Epoch {epoch}')\n",
    "\n",
    "      inputs = inputs.to(device)\n",
    "      targets = targets.to(device)\n",
    "\n",
    "      outputs = model(inputs)\n",
    "\n",
    "      loss = loss_fn(outputs, targets)\n",
    "\n",
    "      loss.backward()\n",
    "\n",
    "      optimizer.step()\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      loss_train.update(loss.item(), n=len(targets))\n",
    "      metric.update(outputs, targets)\n",
    "\n",
    "      tepoch.set_postfix(loss=loss_train.avg, metric=metric.compute().item())\n",
    "\n",
    "  return model, loss_train.avg, metric.compute().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9HgVWslPGsH"
   },
   "source": [
    "# 🔴 **Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TsszJ7GVj2l3"
   },
   "source": [
    "🔰 This is the template for evaluation function, change it if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uV0_67_ZQ0xf"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, loss_fn, metric):\n",
    "  model.eval()\n",
    "  loss_eval = AverageMeter()\n",
    "  metric.reset()\n",
    "\n",
    "  with torch.inference_mode():\n",
    "    for inputs, targets in test_loader:\n",
    "      inputs = inputs.to(device)\n",
    "      targets = targets.to(device)\n",
    "\n",
    "      outputs = model(inputs)\n",
    "\n",
    "      loss = loss_fn(outputs, targets)\n",
    "      loss_eval.update(loss.item(), n=len(targets))\n",
    "\n",
    "      metric(outputs, targets)\n",
    "\n",
    "  return loss_eval.avg, metric.compute().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_5f69nwPtY2"
   },
   "source": [
    "# 🔴 **Training Process 〽️**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "De7VreNxQdct"
   },
   "source": [
    "## 🟠 Finding Hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpJ3wtyctQJH"
   },
   "source": [
    "### 🟡 **Step 1:** Calculate the loss for an untrained model using a few batches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QnE4F4GkzzaR"
   },
   "outputs": [],
   "source": [
    "model =\n",
    "\n",
    "inputs, targets = next(iter(train_set))\n",
    "inputs = inputs.to(device)\n",
    "targets = targets.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "  outputs = model(inputs)\n",
    "  loss = loss_fn(outputs, targets)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BrHQCv7q7LF_"
   },
   "source": [
    "### 🟡 **Step 2:** Try to train and overfit the model on a small subset of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G0ji0MXsWaPt"
   },
   "outputs": [],
   "source": [
    "model =\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kPRZQpPWJ2qv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bNrg4d9hWaPt"
   },
   "outputs": [],
   "source": [
    "num_epochs = ...\n",
    "for epoch in range(num_epochs):\n",
    "  model, _, _ = train_one_epoch(model, ..., loss_fn, optimizer, metric, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLT4w0ZfAhlJ"
   },
   "source": [
    "### 🟡 **Step 3:** Train the model for a limited number of epochs, experimenting with various learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jxz5DXoj61mg"
   },
   "outputs": [],
   "source": [
    "num_epochs =\n",
    "\n",
    "for lr in [...]:\n",
    "  print(f'LR={lr}')\n",
    "\n",
    "  model =\n",
    "  optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=1e-4, momentum=0.9)\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "    model, _, _ = train_one_epoch(model, train_set, loss_fn, optimizer, metric, epoch)\n",
    "\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uC2GhaXfA8vC"
   },
   "source": [
    "### 🟡 Step 4: Create a small grid using the weight decay and the best learning rate.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7UeNW3WWaPu"
   },
   "outputs": [],
   "source": [
    "num_epochs =\n",
    "\n",
    "for lr in [...]:\n",
    "  for wd in [...]:\n",
    "    print(f'LR={lr}, WD={wd}')\n",
    "\n",
    "    model =\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "      model, loss, _ = train_one_epoch(model, train_loader, loss_fn, optimizer, epoch)\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mjd9Z3N1ef3I"
   },
   "source": [
    "### 🟡 Step 5: Train model for longer epochs using the best model from step 4.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IWgkMgC6JWpU"
   },
   "outputs": [],
   "source": [
    "model ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YVwLp-02JWpV"
   },
   "outputs": [],
   "source": [
    "lr =\n",
    "wd =\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zqxSVVB7JWpW"
   },
   "outputs": [],
   "source": [
    "loss_train_hist = []\n",
    "loss_valid_hist = []\n",
    "\n",
    "metric_train_hist = []\n",
    "metric_valid_hist = []\n",
    "\n",
    "best_loss_valid = torch.inf\n",
    "epoch_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eVqS9SEPJWpW"
   },
   "outputs": [],
   "source": [
    "num_epochs =\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  # Train\n",
    "  model, loss_train, metric_train = train_one_epoch(model,\n",
    "                                                 train_set,\n",
    "                                                 loss_fn,\n",
    "                                                 optimizer,\n",
    "                                                 metric,\n",
    "                                                 epoch)\n",
    "  # Validation\n",
    "  loss_valid, metric_valid = evaluate(model,\n",
    "                                     valid_set,\n",
    "                                     loss_fn,\n",
    "                                     metric)\n",
    "\n",
    "  loss_train_hist.append(loss_train)\n",
    "  loss_valid_hist.append(loss_valid)\n",
    "\n",
    "  metric_train_hist.append(metric_train)\n",
    "  metric_valid_hist.append(metric_valid)\n",
    "\n",
    "  if loss_valid < best_loss_valid:\n",
    "    torch.save(model, f'model.pt')\n",
    "    best_loss_valid = loss_valid\n",
    "    print('Model Saved!')\n",
    "\n",
    "  print(f'Valid: Loss = {loss_valid:.4}, Metric = {metric_valid:.4}')\n",
    "  print()\n",
    "\n",
    "  epoch_counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rjGQ-M02cusP"
   },
   "source": [
    "## 🟠 Main Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4AdYaMU4x34g"
   },
   "source": [
    "🔰 Define model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JCtZXDybxexf"
   },
   "outputs": [],
   "source": [
    "model ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AUKZRiQPxqrB"
   },
   "source": [
    "🔰 Define optimizer and Set learning rate and weight decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bowjVB5yIXUP"
   },
   "outputs": [],
   "source": [
    "lr =\n",
    "wd =\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AUyFFIzlyaiB"
   },
   "source": [
    "🔰 Write code to train the model for `num_epochs` epoches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CAXagB4yvtZd"
   },
   "outputs": [],
   "source": [
    "loss_train_hist = []\n",
    "loss_valid_hist = []\n",
    "\n",
    "metric_train_hist = []\n",
    "metric_valid_hist = []\n",
    "\n",
    "best_loss_valid = torch.inf\n",
    "epoch_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PovABWnU3ld0"
   },
   "outputs": [],
   "source": [
    "num_epochs =\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  # Train\n",
    "  model, loss_train, metric_train = train_one_epoch(model,\n",
    "                                                 train_set,\n",
    "                                                 loss_fn,\n",
    "                                                 optimizer,\n",
    "                                                 metric,\n",
    "                                                 epoch)\n",
    "  # Validation\n",
    "  loss_valid, metric_valid = evaluate(model,\n",
    "                                     valid_set,\n",
    "                                     loss_fn,\n",
    "                                     metric)\n",
    "\n",
    "  loss_train_hist.append(loss_train)\n",
    "  loss_valid_hist.append(loss_valid)\n",
    "\n",
    "  metric_train_hist.append(metric_train)\n",
    "  metric_valid_hist.append(metric_valid)\n",
    "\n",
    "  if loss_valid < best_loss_valid:\n",
    "    torch.save(model, f'model.pt')\n",
    "    best_loss_valid = loss_valid\n",
    "    print('Model Saved!')\n",
    "\n",
    "  print(f'Valid: Loss = {loss_valid:.4}, Metric = {metric_valid:.4}')\n",
    "  print()\n",
    "\n",
    "  epoch_counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oK20iNRI3Xxb"
   },
   "source": [
    "## 🟠 Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKlLvCwuzEAA"
   },
   "source": [
    "🔰 Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KYFzTsdIOkVp"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.plot(range(epoch_counter), loss_train_hist, 'r-', label='Train')\n",
    "plt.plot(range(epoch_counter), loss_valid_hist, 'b-', label='Validation')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZ9UIdmkfxlA"
   },
   "source": [
    "# 🔴 **Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SO8iPWH1zVYn"
   },
   "source": [
    "🔰 Test your model using data from the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "35sn67IhKcm_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FzcQQwFuar_7"
   },
   "source": [
    "# 🔴 **Generate**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jh2_9jUp0GF4"
   },
   "source": [
    "🔰 Your mission is to write a `generate` function and use a desired sentence to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pskvb--R-wJ0"
   },
   "outputs": [],
   "source": [
    "model_path = 'model.pt'\n",
    "model = torch.load(model_path)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5SvSDLal8YB"
   },
   "outputs": [],
   "source": [
    "def generate(prompt, max_seq_len, temperature, model, tokenizer, vocab, seed=None):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pVedneOVD6ul"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP0CINCFn69a6yshcTfxPZT",
   "collapsed_sections": [
    "w_a3OXnSeV0z",
    "RwaY_YcgRayy",
    "RTql4Ftiunfr",
    "ujIVtjsYvxOI",
    "wCi-ofSLCzop",
    "B29jrEvwRqXA",
    "A3rnR739GbYb",
    "a4HyLPqcsF43",
    "cfBasjQCE_aI",
    "idRexFij4wgN",
    "PgLgP04P4-aX",
    "NCQjacybOfqV",
    "3ttl0AK3Hvyh",
    "24qT-sgUO2-d",
    "W0QNbC0YPCKZ",
    "G9HgVWslPGsH",
    "o_5f69nwPtY2",
    "De7VreNxQdct",
    "lpJ3wtyctQJH",
    "BrHQCv7q7LF_",
    "BLT4w0ZfAhlJ",
    "uC2GhaXfA8vC",
    "Mjd9Z3N1ef3I",
    "rjGQ-M02cusP",
    "oK20iNRI3Xxb",
    "KZ9UIdmkfxlA",
    "FzcQQwFuar_7"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
