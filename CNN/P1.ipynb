{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T16:33:09.497957Z",
     "iopub.status.busy": "2024-12-11T16:33:09.497040Z",
     "iopub.status.idle": "2024-12-11T16:33:09.504944Z",
     "shell.execute_reply": "2024-12-11T16:33:09.503841Z",
     "shell.execute_reply.started": "2024-12-11T16:33:09.497906Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import time\n",
    "\n",
    "import importlib\n",
    "import utils.utils as utils\n",
    "\n",
    "importlib.reload(utils)\n",
    "from utils.utils import (\n",
    "    accuracy,\n",
    "    train,\n",
    "    combined_train,\n",
    "    test,\n",
    "    plot_acc,\n",
    "    plot_loss,\n",
    "    plot_confusion_matrix,\n",
    "    save_model,\n",
    "    get_feature_maps,\n",
    "    visualize_feature_maps,\n",
    "    plot_images,\n",
    "    plot_feature_maps,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading CIFAR-10 Dataset + Preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T16:33:09.507694Z",
     "iopub.status.busy": "2024-12-11T16:33:09.506947Z",
     "iopub.status.idle": "2024-12-11T16:33:09.516342Z",
     "shell.execute_reply": "2024-12-11T16:33:09.515524Z",
     "shell.execute_reply.started": "2024-12-11T16:33:09.507652Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class OneHotEncode:\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def __call__(self, label):\n",
    "        return F.one_hot(torch.tensor(label), num_classes=self.num_classes).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T16:33:09.526323Z",
     "iopub.status.busy": "2024-12-11T16:33:09.525603Z",
     "iopub.status.idle": "2024-12-11T16:33:11.441090Z",
     "shell.execute_reply": "2024-12-11T16:33:11.440219Z",
     "shell.execute_reply.started": "2024-12-11T16:33:09.526283Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_size = 50000\n",
    "val_size = 10000\n",
    "test_size = 10000\n",
    "mean = [0.5, 0.5, 0.5]\n",
    "std = [0.5, 0.5, 0.5]\n",
    "num_classes = 10\n",
    "\n",
    "torch.manual_seed(13)\n",
    "np.random.seed(13)\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize(mean=mean, std=std)]\n",
    ")\n",
    "\n",
    "label_transform = OneHotEncode(num_classes=num_classes)\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    "    target_transform=label_transform,\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    "    target_transform=label_transform,\n",
    ")\n",
    "\n",
    "train_subset, val_subset = random_split(\n",
    "    train_dataset, [train_size - val_size, val_size]\n",
    ")\n",
    "test_subset, _ = random_split(test_dataset, [test_size, len(test_dataset) - test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T16:33:11.443136Z",
     "iopub.status.busy": "2024-12-11T16:33:11.442850Z",
     "iopub.status.idle": "2024-12-11T16:33:11.448117Z",
     "shell.execute_reply": "2024-12-11T16:33:11.447224Z",
     "shell.execute_reply.started": "2024-12-11T16:33:11.443105Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "classes = train_dataset.classes\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T16:33:11.449381Z",
     "iopub.status.busy": "2024-12-11T16:33:11.449100Z",
     "iopub.status.idle": "2024-12-11T16:33:12.071792Z",
     "shell.execute_reply": "2024-12-11T16:33:12.070976Z",
     "shell.execute_reply.started": "2024-12-11T16:33:11.449329Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "samples = {}\n",
    "\n",
    "for image, label in train_subset:\n",
    "    label = torch.argmax(label).item()\n",
    "    if label not in samples:\n",
    "        samples[f\"{classes[label]}: {label}\"] = image\n",
    "    if len(samples) == len(classes):\n",
    "        break\n",
    "\n",
    "plot_images(list(samples.values()), mean, std, list(samples.keys()), \"Random Samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T16:33:12.073069Z",
     "iopub.status.busy": "2024-12-11T16:33:12.072811Z",
     "iopub.status.idle": "2024-12-11T16:33:12.078898Z",
     "shell.execute_reply": "2024-12-11T16:33:12.078022Z",
     "shell.execute_reply.started": "2024-12-11T16:33:12.073044Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_subset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_subset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_subset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T16:33:12.080940Z",
     "iopub.status.busy": "2024-12-11T16:33:12.080648Z",
     "iopub.status.idle": "2024-12-11T16:33:12.090615Z",
     "shell.execute_reply": "2024-12-11T16:33:12.089812Z",
     "shell.execute_reply.started": "2024-12-11T16:33:12.080896Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {device.type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T16:33:12.092239Z",
     "iopub.status.busy": "2024-12-11T16:33:12.091658Z",
     "iopub.status.idle": "2024-12-11T16:33:12.104751Z",
     "shell.execute_reply": "2024-12-11T16:33:12.104028Z",
     "shell.execute_reply.started": "2024-12-11T16:33:12.092200Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BaselineModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaselineModel, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(64 * 14 * 14, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "baseline_model = BaselineModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(params=baseline_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T16:33:12.147802Z",
     "iopub.status.busy": "2024-12-11T16:33:12.147552Z",
     "iopub.status.idle": "2024-12-11T16:40:14.001633Z",
     "shell.execute_reply": "2024-12-11T16:40:14.000758Z",
     "shell.execute_reply.started": "2024-12-11T16:33:12.147760Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "epochs = 30\n",
    "\n",
    "train_losses, train_accuracies, validation_losses, validation_accuracies = train(\n",
    "    model=baseline_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    epochs=epochs,\n",
    "    log=True,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"time: {np.round(end_time - start_time, 2)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T16:40:14.003206Z",
     "iopub.status.busy": "2024-12-11T16:40:14.002870Z",
     "iopub.status.idle": "2024-12-11T16:40:14.363305Z",
     "shell.execute_reply": "2024-12-11T16:40:14.362510Z",
     "shell.execute_reply.started": "2024-12-11T16:40:14.003166Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_loss(train_losses, validation_losses, epochs=epochs)\n",
    "plot_acc(train_accuracies, validation_accuracies, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T16:40:14.364753Z",
     "iopub.status.busy": "2024-12-11T16:40:14.364374Z",
     "iopub.status.idle": "2024-12-11T16:40:14.372650Z",
     "shell.execute_reply": "2024-12-11T16:40:14.371773Z",
     "shell.execute_reply.started": "2024-12-11T16:40:14.364711Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "save_model(baseline_model, \"./baseline.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T16:40:14.374002Z",
     "iopub.status.busy": "2024-12-11T16:40:14.373658Z",
     "iopub.status.idle": "2024-12-11T16:40:14.404467Z",
     "shell.execute_reply": "2024-12-11T16:40:14.403792Z",
     "shell.execute_reply.started": "2024-12-11T16:40:14.373962Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ImprovedModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImprovedModel, self).__init__()\n",
    "\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        # 3 * 32 * 32 -> 64 * 30 * 30\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3)\n",
    "        # 64 * 15 * 15 -> 128 * 13 * 13\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
    "        # 128 * 6 * 6 -> 256 * 4 * 4\n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(64 * 2 * 2, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "improved_model = ImprovedModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(params=improved_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T16:40:14.407379Z",
     "iopub.status.busy": "2024-12-11T16:40:14.407100Z",
     "iopub.status.idle": "2024-12-11T16:47:49.427541Z",
     "shell.execute_reply": "2024-12-11T16:47:49.426272Z",
     "shell.execute_reply.started": "2024-12-11T16:40:14.407328Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "epochs = 30\n",
    "\n",
    "train_losses, train_accuracies, validation_losses, validation_accuracies = train(\n",
    "    model=improved_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    epochs=epochs,\n",
    "    log=True,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"time: {np.round(end_time - start_time, 2)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T16:47:49.429121Z",
     "iopub.status.busy": "2024-12-11T16:47:49.428805Z",
     "iopub.status.idle": "2024-12-11T16:47:49.777048Z",
     "shell.execute_reply": "2024-12-11T16:47:49.776257Z",
     "shell.execute_reply.started": "2024-12-11T16:47:49.429091Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_loss(train_losses, validation_losses, epochs=epochs)\n",
    "plot_acc(train_accuracies, validation_accuracies, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T16:47:49.778403Z",
     "iopub.status.busy": "2024-12-11T16:47:49.778036Z",
     "iopub.status.idle": "2024-12-11T16:47:49.809989Z",
     "shell.execute_reply": "2024-12-11T16:47:49.809130Z",
     "shell.execute_reply.started": "2024-12-11T16:47:49.778361Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "save_model(improved_model, \"./improvedmodel.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Batch Normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T16:47:49.811194Z",
     "iopub.status.busy": "2024-12-11T16:47:49.810938Z",
     "iopub.status.idle": "2024-12-11T16:47:49.841888Z",
     "shell.execute_reply": "2024-12-11T16:47:49.841064Z",
     "shell.execute_reply.started": "2024-12-11T16:47:49.811169Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BnModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BnModel, self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        # 3 * 32 * 32 -> 64 * 28 * 28\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        # 64 * 14 * 14 -> 64 * 12 * 12\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        # 64 * 6 * 6 -> 63 * 4 * 4\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.averagepool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 64 * 4 * 4)\n",
    "        self.fc2 = nn.Linear(64 * 4 * 4, 64 * 4 * 4)\n",
    "        self.fc3 = nn.Linear(64 * 4 * 4, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.averagepool(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "bn_model = BnModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(params=bn_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T16:47:49.843102Z",
     "iopub.status.busy": "2024-12-11T16:47:49.842854Z",
     "iopub.status.idle": "2024-12-11T16:55:43.621689Z",
     "shell.execute_reply": "2024-12-11T16:55:43.620816Z",
     "shell.execute_reply.started": "2024-12-11T16:47:49.843077Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "epochs = 30\n",
    "\n",
    "train_losses, train_accuracies, validation_losses, validation_accuracies = train(\n",
    "    model=bn_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    epochs=epochs,\n",
    "    log=True,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"time: {np.round(end_time - start_time, 2)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T16:55:43.623364Z",
     "iopub.status.busy": "2024-12-11T16:55:43.622985Z",
     "iopub.status.idle": "2024-12-11T16:55:43.971506Z",
     "shell.execute_reply": "2024-12-11T16:55:43.970595Z",
     "shell.execute_reply.started": "2024-12-11T16:55:43.623300Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_loss(train_losses, validation_losses, epochs=epochs)\n",
    "plot_acc(train_accuracies, validation_accuracies, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T16:55:43.972782Z",
     "iopub.status.busy": "2024-12-11T16:55:43.972438Z",
     "iopub.status.idle": "2024-12-11T16:55:44.002995Z",
     "shell.execute_reply": "2024-12-11T16:55:44.002003Z",
     "shell.execute_reply.started": "2024-12-11T16:55:43.972743Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "save_model(bn_model, \"./bnmodel.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T16:55:44.004337Z",
     "iopub.status.busy": "2024-12-11T16:55:44.004036Z",
     "iopub.status.idle": "2024-12-11T16:55:44.032970Z",
     "shell.execute_reply": "2024-12-11T16:55:44.032342Z",
     "shell.execute_reply.started": "2024-12-11T16:55:44.004311Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DoModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DoModel, self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        # 3 * 32 * 32 -> 64 * 28 * 28\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        # 64 * 14 * 14 -> 64 * 14 * 14\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        # 64 * 6 * 6 -> 63 * 4 * 4\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.averagepool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 64 * 4 * 4)\n",
    "        self.fc2 = nn.Linear(64 * 4 * 4, 64 * 4 * 4)\n",
    "        self.fc3 = nn.Linear(64 * 4 * 4, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.averagepool(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "do_model = DoModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(params=do_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T16:55:44.034562Z",
     "iopub.status.busy": "2024-12-11T16:55:44.033954Z",
     "iopub.status.idle": "2024-12-11T17:03:44.595436Z",
     "shell.execute_reply": "2024-12-11T17:03:44.594577Z",
     "shell.execute_reply.started": "2024-12-11T16:55:44.034520Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "epochs = 30\n",
    "\n",
    "train_losses, train_accuracies, validation_losses, validation_accuracies = train(\n",
    "    model=do_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    epochs=epochs,\n",
    "    log=True,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"time: {np.round(end_time - start_time, 2)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T17:03:44.596913Z",
     "iopub.status.busy": "2024-12-11T17:03:44.596637Z",
     "iopub.status.idle": "2024-12-11T17:03:44.935509Z",
     "shell.execute_reply": "2024-12-11T17:03:44.934609Z",
     "shell.execute_reply.started": "2024-12-11T17:03:44.596886Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_loss(train_losses, validation_losses, epochs=epochs)\n",
    "plot_acc(train_accuracies, validation_accuracies, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T17:03:44.937560Z",
     "iopub.status.busy": "2024-12-11T17:03:44.936791Z",
     "iopub.status.idle": "2024-12-11T17:03:44.967383Z",
     "shell.execute_reply": "2024-12-11T17:03:44.966472Z",
     "shell.execute_reply.started": "2024-12-11T17:03:44.937503Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "save_model(bn_model, \"./domodel.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test and Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T17:03:44.987502Z",
     "iopub.status.busy": "2024-12-11T17:03:44.987261Z",
     "iopub.status.idle": "2024-12-11T17:03:58.566996Z",
     "shell.execute_reply": "2024-12-11T17:03:58.566152Z",
     "shell.execute_reply.started": "2024-12-11T17:03:44.987478Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_loss, base_accuracy, base_preds, base_labels = test(\n",
    "    model=baseline_model, test_loader=test_loader, criterion=criterion, device=device\n",
    ")\n",
    "print(\"baseline model:\")\n",
    "print(f\"loss= {np.round(base_loss, 3)}, accuracy= {np.round(base_accuracy, 3)}\")\n",
    "plot_confusion_matrix(\n",
    "    base_labels, base_preds, class_names=classes, title=\"baseline model\"\n",
    ")\n",
    "\n",
    "\n",
    "improved_loss, improved_accuracy, improved_preds, improved_labels = test(\n",
    "    model=improved_model, test_loader=test_loader, criterion=criterion, device=device\n",
    ")\n",
    "print(\"improved model:\")\n",
    "print(f\"loss= {np.round(improved_loss, 3)}, accuracy= {np.round(improved_accuracy, 3)}\")\n",
    "plot_confusion_matrix(\n",
    "    improved_labels, improved_preds, class_names=classes, title=\"improved model\"\n",
    ")\n",
    "\n",
    "\n",
    "bn_loss, bn_accuracy, bn_preds, bn_labels = test(\n",
    "    model=bn_model, test_loader=test_loader, criterion=criterion, device=device\n",
    ")\n",
    "print(\"batch normalization model\")\n",
    "print(f\"loss= {np.round(bn_loss, 3)}, accuracy= {np.round(bn_accuracy, 3)}\")\n",
    "plot_confusion_matrix(\n",
    "    bn_labels, bn_preds, class_names=classes, title=\"batch normalization model\"\n",
    ")\n",
    "\n",
    "\n",
    "do_loss, do_accuracy, do_preds, do_labels = test(\n",
    "    model=do_model, test_loader=test_loader, criterion=criterion, device=device\n",
    ")\n",
    "print(\"dropout model\")\n",
    "print(f\"loss= {np.round(do_loss, 3)}, accuracy= {np.round(do_accuracy, 3)}\")\n",
    "plot_confusion_matrix(do_labels, do_preds, class_names=classes, title=\"dropout model\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
