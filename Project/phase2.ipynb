{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7032396,"sourceType":"datasetVersion","datasetId":4045126}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q torch opencv-python pandas\n!pip install -q ultralytics matplotlib\n!pip install -q huggingface_hub","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"42SxdmZiUdAF","outputId":"d797e407-dee8-4393-91bb-aba526d7dbbd","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Kaggle","metadata":{}},{"cell_type":"code","source":"import kagglehub\n\nroot_dir = \"/kaggle/working\"\n\ndataset_dir = kagglehub.dataset_download(\"ayushspai/sportsmot\")\n\nprint(\"Path to dataset files:\", dataset_dir)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Colab","metadata":{}},{"cell_type":"code","source":"# !pip install -q kaggle\n# !kaggle datasets download -d ayushspai/sportsmot -q\n# !unzip -q sportsmot.zip -d SportsMOT\n# !rm sportsmot.zip\n# !mv /content/SportsMOT/sportsmot_publish/dataset/val/* /content/SportsMOT/sportsmot_publish/dataset/train > /dev/null 2>&1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"02Ksun9RUdAH","outputId":"8da51fea-2e29-425c-a19d-20c09d5b27e4","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport torch\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision.transforms import Compose, ToTensor, Normalize, RandomHorizontalFlip, ColorJitter\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\nfrom ultralytics import YOLO\n\nimport shutil\n\nfrom huggingface_hub import HfApi, Repository, hf_hub_download\n\nimport time","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TSZTgPdcUdAI","outputId":"920f2f50-9001-4d2d-efbf-08e1e38d9dcc","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Dataset","metadata":{"id":"y931dFU6UdAI"}},{"cell_type":"code","source":"def load_football_sequences(splits_dir):\n    football_file = os.path.join(splits_dir, \"football.txt\")\n    with open(football_file, \"r\") as f:\n        football_sequences = f.read().splitlines()\n    return set(football_sequences)\n\ndef copy_football_data(root_dir, dataset_dir):\n    destination_dir = os.path.join(root_dir, \"sportsmot\")\n    os.makedirs(destination_dir, exist_ok=True)\n    \n    splits_dir = os.path.join(dataset_dir, \"sportsmot_publish\", \"splits_txt\")\n    football_sequences = load_football_sequences(splits_dir)\n    shutil.copytree(splits_dir, os.path.join(destination_dir, \"splits_txt\"), dirs_exist_ok=True)\n    \n    for split in [\"train\", \"val\", \"test\"]:\n        split_dir = os.path.join(dataset_dir, \"sportsmot_publish\", \"dataset\", split)\n        dest_split_dir = os.path.join(destination_dir, split)\n        os.makedirs(dest_split_dir, exist_ok=True)\n        \n        if not os.path.exists(split_dir):\n            continue\n\n        sequences = os.listdir(split_dir)\n        for seq in sequences:\n            seq_path = os.path.join(split_dir, seq)\n            dest_seq_path = os.path.join(dest_split_dir, seq)\n            \n            if seq in football_sequences:\n                shutil.copytree(seq_path, dest_seq_path, dirs_exist_ok=True)\n\n    print(\"Football data copying complete!\")\n    return destination_dir\n\ndataset_dir = copy_football_data(root_dir, dataset_dir)\nprint(\"Path to dataset files:\", dataset_dir)","metadata":{"id":"NvfZr-qddm0d","outputId":"d1a1196d-9495-4029-b49b-89b630f8b3bd","colab":{"base_uri":"https://localhost:8080/"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Object Detection","metadata":{"id":"Zh95MlssUdAK"}},{"cell_type":"markdown","source":"### Converting Dataset","metadata":{}},{"cell_type":"code","source":"def convert_to_yolo_format(root_dir, dataset_dir, split):\n    os.makedirs(os.path.join(root_dir, \"dataset\", \"images\", split), exist_ok=True)\n    os.makedirs(os.path.join(root_dir, \"dataset\", \"labels\", split), exist_ok=True)\n\n    splits_dir = os.path.join(dataset_dir, \"splits_txt\")\n    football_sequences = load_football_sequences(splits_dir)\n\n    for seq in football_sequences:\n        seq_path = os.path.join(dataset_dir, split, seq)\n        gt_file = os.path.join(seq_path, \"gt\", \"gt.txt\")\n\n        if not os.path.exists(gt_file):\n            continue\n\n        df = pd.read_csv(gt_file, header=None)\n        df.columns = [\n            \"frame_id\", \"object_id\", \"x\", \"y\", \"w\", \"h\",\n            \"conf\", \"class_id\", \"visibility\"\n        ]\n\n        for frame_id, group in df.groupby(\"frame_id\"):\n            img_path = os.path.join(seq_path, \"img1\", f\"{frame_id:06d}.jpg\")\n            if not os.path.exists(img_path):\n                continue\n\n            img = cv2.imread(img_path)\n            img_name = f\"{seq}_{frame_id:06d}.jpg\"\n            cv2.imwrite(os.path.join(root_dir, \"dataset\", \"images\", split, img_name), img)\n\n            label_file = os.path.join(root_dir, \"dataset\", \"labels\", split, f\"{seq}_{frame_id:06d}.txt\")\n            with open(label_file, \"w\") as f:\n                for _, row in group.iterrows():\n                    x_center = (row[\"x\"] + row[\"w\"] / 2) / img.shape[1]\n                    y_center = (row[\"y\"] + row[\"h\"] / 2) / img.shape[0]\n                    width = row[\"w\"] / img.shape[1]\n                    height = row[\"h\"] / img.shape[0]\n                    f.write(f\"{int(row['class_id'])} {x_center} {y_center} {width} {height}\\n\")\n\nconvert_to_yolo_format(root_dir, dataset_dir, \"train\")\nconvert_to_yolo_format(root_dir, dataset_dir, \"val\")\nconvert_to_yolo_format(root_dir, dataset_dir, \"test\")","metadata":{"id":"O_yzqtrGXBzD","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### YOLO","metadata":{}},{"cell_type":"code","source":"def create_yaml_file(dataset_dir, class_names):\n    yaml_content = f\"\"\"\npath: {dataset_dir}\ntrain: images/train\nval: images/val\ntest: images/test\n\nnc: {len(class_names)}\nnames: {class_names}\n\"\"\"\n    yaml_path = os.path.join(dataset_dir, \"dataset.yaml\")\n    with open(yaml_path, \"w\") as f:\n        f.write(yaml_content)\n\n    print(f\"YAML file created at: {yaml_path}\")\n\nyolo_dataset_dir = \"/kaggle/working/dataset\"\nclass_names = ['player', 'referee', 'ball', 'other'] # TODO\n\ncreate_yaml_file(yolo_dataset_dir, class_names)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pe32ad7kh4GI","outputId":"fb887feb-f420-402e-d18d-8591c51487ec","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = YOLO(\"yolov8n.pt\")\n\nresults = model.train(\n    data=f\"{yolo_dataset_dir}/dataset.yaml\",\n    epochs=50,\n    imgsz=1280,\n    batch=16,\n    name=\"yolov8_football\",\n    verbose=False\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bxSfOEkxbcRK","outputId":"758b6b2f-6860-485a-a317-7fbd3a535a33","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Logs","metadata":{}},{"cell_type":"code","source":"def plot_logs(results_path):\n    logs = pd.read_csv(results_path)\n\n    plt.figure(figsize=(10, 5))\n    plt.plot(logs[\"epoch\"], logs[\"train/box_loss\"], label=\"Train Box Loss\")\n    plt.plot(logs[\"epoch\"], logs[\"val/box_loss\"], label=\"Validation Box Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"Training and Validation Loss\")\n    plt.legend()\n    plt.show()\n\n    plt.figure(figsize=(10, 5))\n    plt.plot(logs[\"epoch\"], logs[\"metrics/mAP_0.5\"], label=\"mAP@0.5\")\n    plt.plot(logs[\"epoch\"], logs[\"metrics/mAP_0.5:0.95\"], label=\"mAP@0.5:0.95\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"mAP\")\n    plt.title(\"Mean Average Precision\")\n    plt.legend()\n    plt.show()\n\nresults_path = \"/kaggle/working/runs/detect/yolov8_football/results.csv\"\nplot_logs(results_path)","metadata":{"id":"VPieolPiiJqc"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Testing and Validation","metadata":{}},{"cell_type":"code","source":"model_path = \"/kaggle/working/runs/detect/yolov8_football/weights/best.pt\"\n\nmodel = YOLO(model_path)\n\nresults = model(\"/kaggle/working/dataset/images/test/seq101_000001.jpg\") # TODO\n\nfor result in results:\n    result.show()\n    result.save(\"output.jpg\")","metadata":{"id":"doBifmGaiMSL"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metrics = model.val()\n\nprint(f\"mAP@0.5: {metrics.box.map}\")\nprint(f\"mAP@0.5:0.95: {metrics.box.map_50_95}\")","metadata":{"id":"g3sbL4CqiPHm"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Saving to Hugging Face\n","metadata":{"id":"gwRlxT9DO253"}},{"cell_type":"code","source":"!huggingface-cli login","metadata":{"id":"O3QyXLvYO7S-"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_path = \"/content/runs/detect/yolov8_football/weights/best.pt\"\nrepo_id = \"ParsaGh/yolov8_football\"\nrepo_name = \"yolov8_football\"\n\nmodel = YOLO(model_path)\n\nrepo = Repository(l\n    ocal_dir=yolov8_football,\n    clone_from=repo_id,\n    use_auth_token=True\n)\nos.system(f\"cp {model_path} {repo_name}/\")\nrepo.push_to_hub(commit_message=\"Upload YOLOv8-Football model\")","metadata":{"id":"CRVnhYZIO-7f"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loading From Hugging Face","metadata":{"id":"nDBjsKSGQXd0"}},{"cell_type":"code","source":"model_path = hf_hub_download(\n    repo_id=repo_id,\n    filename=\"best.pt\",\n    use_auth_token=True,\n)\n\nmodel = YOLO(model_path)\n\n# results = model(\"path_to_test_image.jpg\") #TODO\n# results.show()","metadata":{"id":"7fRqTtnmQb8c"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Single Object Tracking","metadata":{"id":"Jjg8E0uTkPd8"}},{"cell_type":"code","source":"class SingleObjectTracker:\n    def __init__(self, yolo_weights='best.pt'):\n        self.yolo = YOLO(yolo_weights)\n        self.tracker = cv2.TrackerCSRT_create()\n        self.target_class = 0\n        self.last_valid_bbox = None\n        self.frames_since_last_detection = 0\n        self.heatmap = None\n        self.heatmap_alpha = 0.5\n\n    def track(self, frame):\n        success, bbox = self.tracker.update(frame)\n\n        if not success or self._needs_reinitialization(bbox):\n            print(\"Attempting recovery...\")\n            success, bbox = self._reinitialize_tracker(frame)\n\n        if success:\n            self.last_valid_bbox = bbox\n            self.frames_since_last_detection = 0\n        else:\n            self.frames_since_last_detection += 1\n\n        return success, bbox\n\n    def _needs_reinitialization(self, bbox):\n        if bbox[2] <= 0 or bbox[3] <= 0:\n            return True\n        if self.last_valid_bbox:\n            # Check position change > 50% of frame size\n            dx = abs(bbox[0] - self.last_valid_bbox[0])/1280\n            dy = abs(bbox[1] - self.last_valid_bbox[1])/720\n            return dx > 0.5 or dy > 0.5\n        return False\n\n    def _reinitialize_tracker(self, frame):\n        # Search in last known position area\n        if self.last_valid_bbox:\n            x, y, w, h = self.last_valid_bbox\n            search_region = frame[int(y):int(y+h), int(x):int(x+w)]\n            results = self.yolo(search_region, verbose=False)[0]\n        else:\n            results = self.yolo(frame, verbose=False)[0]\n\n        # Filter and select best detection\n        athlete_boxes = []\n        for box, cls, conf in zip(results.boxes.xywh, results.boxes.cls, results.boxes.conf):\n            if cls == self.target_class and conf > 0.5:\n                athlete_boxes.append((conf, box.cpu().numpy()))\n\n        if athlete_boxes:\n            # Select closest to last position or highest confidence\n            best_conf, best_box = max(athlete_boxes, key=lambda x: x[0])\n            x_center, y_center, w, h = best_box\n            x = x_center - w/2 + (self.last_valid_bbox[0] if self.last_valid_bbox else 0)\n            y = y_center - h/2 + (self.last_valid_bbox[1] if self.last_valid_bbox else 0)\n            new_bbox = (x, y, w, h)\n            self.tracker = cv2.TrackerCSRT_create()\n            self.tracker.init(frame, new_bbox)\n            return True, new_bbox\n\n        return False, None\n\n    def update_heatmap(self, bbox):\n        if bbox is None:\n            return\n        \n        # Create heatmap if not initialized\n        if self.heatmap is None:\n            self.heatmap = np.zeros((720, 1280), dtype=np.float32)\n        \n        # Extract object center\n        x, y, w, h = bbox\n        center_x = int(x + w/2)\n        center_y = int(y + h/2)\n        \n        # Add Gaussian blur to the center point\n        cv2.circle(self.heatmap, (center_x, center_y), 10, 1, -1)\n        self.heatmap = cv2.GaussianBlur(self.heatmap, (51, 51), 0)\n\n    def draw_heatmap(self, frame):\n        if self.heatmap is None:\n            return frame\n        \n        # Normalize heatmap to 0-255\n        heatmap_norm = cv2.normalize(self.heatmap, None, 0, 255, cv2.NORM_MINMAX)\n        heatmap_norm = np.uint8(heatmap_norm)\n        \n        # Apply color map (Jet for better visualization)\n        heatmap_colored = cv2.applyColorMap(heatmap_norm, cv2.COLORMAP_JET)\n        \n        # Overlay heatmap on the frame\n        overlay = cv2.addWeighted(frame, 1 - self.heatmap_alpha, heatmap_colored, self.heatmap_alpha, 0)\n        return overlay","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Test","metadata":{}},{"cell_type":"code","source":"def play_video(video_path):\n    cap = cv2.VideoCapture(video_path)\n    if not cap.isOpened():\n        print(\"Error: Could not open video file.\")\n        return\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        cv2.imshow('Output Video', frame)\n        if cv2.waitKey(25) & 0xFF == ord('q'):\n            break\n\n    cap.release()\n    cv2.destroyAllWindows()\n    \ndef test_on_sportsmot_frames(frames_dir, output_dir=\"results\"):\n    tracker = SingleObjectTracker('best.pt')\n    \n    os.makedirs(output_dir, exist_ok=True)\n    \n    frame_paths = sorted([os.path.join(frames_dir, f) for f in os.listdir(frames_dir)])\n    \n    frame = cv2.imread(frame_paths[0])\n    if frame is None:\n        raise ValueError(\"No frames found in test directory\")\n    \n    height, width = frame.shape[:2]\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(os.path.join(output_dir, 'tracking_results.mp4'), \n                         fourcc, 25.0, (width, height))\n    \n    for frame_path in frame_paths:\n        frame = cv2.imread(frame_path)\n        if frame is None:\n            continue\n            \n        if tracker.last_valid_bbox is None:\n            bbox = tracker.initialize(frame)\n        else:\n            success, bbox = tracker.track(frame)\n        \n        if bbox is not None:\n            tracker.update_heatmap(bbox)\n        \n        frame_with_heatmap = tracker.draw_heatmap(frame)\n        \n        if bbox is not None:\n            x, y, w, h = [int(v) for v in bbox]\n            cv2.rectangle(frame_with_heatmap, (x, y), (x+w, y+h), (0, 255, 0), 2)\n        \n        out.write(frame_with_heatmap)\n    \n    out.release()\n    print(f\"Results saved to: {os.path.abspath(output_dir)}\")\n    play_video(os.path.join(output_dir, 'tracking_results.mp4')","metadata":{"id":"d-onNQEpkXVD"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sportsmot_test_dir = f\"{dataset_dir}/test/\" # TODO\ntest_on_sportsmot_frames(sportsmot_test_dir)","metadata":{"id":"_Uxrcq2ToU6t"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Conditions Where CSRT Performs Well:\n\n\nSlow Motion: The object moves slowly relative to the frame rate.\n\nMinimal Occlusion: The object is not occluded by other objects.\n\nConsistent Lighting: The lighting conditions remain stable.\n\nDistinct Appearance: The object has a unique appearance compared to the background.\n\n### Conditions Where CSRT Performs Poorly:\n\nFast Motion: The object moves quickly, causing the tracker to lose it.\n\nOcclusion: The object is occluded by other objects or goes out of the frame.\n\nAppearance Changes: The object's appearance changes significantly (e.g., due to lighting or deformation).\n\nSimilar Background: The object blends into the background, making it hard to distinguish.","metadata":{"id":"LqM7jHF6oZNo"}},{"cell_type":"code","source":"","metadata":{"id":"PC333TPhoaNE"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Multiple Object Tracking","metadata":{}},{"cell_type":"code","source":"","metadata":{"id":"SFAunj08sdV4"},"outputs":[],"execution_count":null}]}