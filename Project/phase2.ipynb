{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install torch opencv-python pandas\n",
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!kaggle datasets download -d ayushspai/sportsmot -q\n",
    "!unzip -q sportsmot.zip -d SportsMOT\n",
    "!rm sportsmot.zip\n",
    "!cp -r /content/SportsMOT/sportsmot_publish/dataset/val/* /content/SportsMOT/sportsmot_publish/dataset/train > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, RandomHorizontalFlip, ColorJitter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_football_sequences(splits_dir):\n",
    "    football_file = os.path.join(splits_dir, \"football.txt\")\n",
    "    with open(football_file, \"r\") as f:\n",
    "        all_sequences = f.read().splitlines()\n",
    "\n",
    "    return all_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class FootballDataset(Dataset):\n",
    "    def __init__(self, root_dir, split=\"train\", transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "\n",
    "        splits_dir = os.path.join(root_dir, \"splits_txt\")\n",
    "        self.football_sequences = load_football_sequences(splits_dir)\n",
    "\n",
    "        self.sequences = []\n",
    "        for seq in self.football_sequences:\n",
    "            seq_path = os.path.join(root_dir, \"dataset\", split, seq)\n",
    "            if os.path.exists(seq_path):\n",
    "                self.sequences.append(seq)\n",
    "\n",
    "        self.annotations = {}\n",
    "        for seq in self.sequences:\n",
    "            gt_file = os.path.join(root_dir, \"dataset\", split, seq, \"gt\", \"gt.txt\")\n",
    "            if os.path.exists(gt_file):\n",
    "                self.annotations[seq] = self._load_annotations(gt_file)\n",
    "\n",
    "        self.default_transform = Compose([\n",
    "            ToTensor(),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def _load_annotations(self, gt_file):\n",
    "        df = pd.read_csv(gt_file, header=None)\n",
    "        df.columns = [\n",
    "            \"frame_id\", \"object_id\", \"x\", \"y\", \"w\", \"h\",\n",
    "            \"conf\", \"class_id\", \"visibility\"\n",
    "        ]\n",
    "\n",
    "        annotations = {}\n",
    "        for frame_id, group in df.groupby(\"frame_id\"):\n",
    "            annotations[frame_id] = {\n",
    "                \"boxes\": group[[\"x\", \"y\", \"w\", \"h\"]].values.astype(\"float32\"),\n",
    "                \"object_ids\": group[\"object_id\"].values.astype(\"int32\"),\n",
    "                \"classes\": group[\"class_id\"].values.astype(\"int32\")\n",
    "            }\n",
    "        return annotations\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(len(ann) for ann in self.annotations.values())\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        for seq in self.sequences:\n",
    "            seq_ann = self.annotations[seq]\n",
    "            if idx < len(seq_ann):\n",
    "                frame_id = list(seq_ann.keys())[idx]\n",
    "                break\n",
    "            idx -= len(seq_ann)\n",
    "        else:\n",
    "            raise IndexError(\"Index out of range\")\n",
    "\n",
    "        img_path = os.path.join(self.root_dir, \"dataset\", self.split, seq, \"img1\", f\"{frame_id:06d}.jpg\")\n",
    "        image = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        ann = self.annotations[seq][frame_id]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = self.default_transform(image)\n",
    "\n",
    "        return image, {\n",
    "            \"boxes\": torch.tensor(ann[\"boxes\"]),\n",
    "            \"object_ids\": torch.tensor(ann[\"object_ids\"]),\n",
    "            \"classes\": torch.tensor(ann[\"classes\"]),\n",
    "            \"frame_id\": frame_id,\n",
    "            \"sequence\": seq\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    images = torch.stack([item[0] for item in batch])\n",
    "    targets = [item[1] for item in batch]\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset_dir = \"/content/SportsMOT/sportsmot_publish\"\n",
    "\n",
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = FootballDataset(root_dir=dataset_dir, split=\"train\", transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "valid_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - valid_size\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = random_split(\n",
    "    dataset, [train_size, valid_size, test_size]\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=custom_collate, num_workers=2)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=4, shuffle=False, collate_fn=custom_collate, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=custom_collate, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "len(train_loader), len(test_loader), len(valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
