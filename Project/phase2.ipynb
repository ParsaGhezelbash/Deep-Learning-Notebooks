{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42SxdmZiUdAF",
        "outputId": "d797e407-dee8-4393-91bb-aba526d7dbbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q torch opencv-python pandas\n",
        "!pip install -q kaggle\n",
        "!pip install -q ultralytics matplotlib\n",
        "!pip install -q huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02Ksun9RUdAH",
        "outputId": "8da51fea-2e29-425c-a19d-20c09d5b27e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/ayushspai/sportsmot\n",
            "License(s): MIT\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d ayushspai/sportsmot -q\n",
        "!unzip -q sportsmot.zip -d SportsMOT\n",
        "!rm sportsmot.zip\n",
        "# !mv /content/SportsMOT/sportsmot_publish/dataset/val/* /content/SportsMOT/sportsmot_publish/dataset/train > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSZTgPdcUdAI",
        "outputId": "920f2f50-9001-4d2d-efbf-08e1e38d9dcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, RandomHorizontalFlip, ColorJitter\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "import shutil\n",
        "\n",
        "from huggingface_hub import HfApi, Repository, hf_hub_download\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y931dFU6UdAI"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_football_sequences(splits_dir):\n",
        "    football_file = os.path.join(splits_dir, \"football.txt\")\n",
        "    with open(football_file, \"r\") as f:\n",
        "        football_sequences = f.read().splitlines()\n",
        "    return set(football_sequences)\n",
        "\n",
        "def delete_non_football_data(root_dir):\n",
        "    splits_dir = os.path.join(root_dir, \"splits_txt\")\n",
        "    football_sequences = load_football_sequences(splits_dir)\n",
        "\n",
        "    for split in [\"train\", \"val\", \"test\"]:\n",
        "        split_dir = os.path.join(root_dir, \"dataset\", split)\n",
        "        if not os.path.exists(split_dir):\n",
        "            continue\n",
        "\n",
        "        sequences = os.listdir(split_dir)\n",
        "        for seq in sequences:\n",
        "            seq_path = os.path.join(split_dir, seq)\n",
        "\n",
        "            if seq not in football_sequences:\n",
        "                # print(f\"Deleting non-football sequence: {seq_path}\")\n",
        "                shutil.rmtree(seq_path)\n",
        "\n",
        "    print(\"Non-football data deletion complete!\")\n",
        "\n",
        "dataset_dir = \"/content/SportsMOT/sportsmot_publish\"\n",
        "delete_non_football_data(dataset_dir)"
      ],
      "metadata": {
        "id": "NvfZr-qddm0d",
        "outputId": "d1a1196d-9495-4029-b49b-89b630f8b3bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-football data deletion complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh95MlssUdAK"
      },
      "source": [
        "## Object Detection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_yolo_format(root_dir, mot_dir, split):\n",
        "    os.makedirs(os.path.join(root_dir, \"dataset\", \"images\", split), exist_ok=True)\n",
        "    os.makedirs(os.path.join(root_dir, \"dataset\", \"labels\", split), exist_ok=True)\n",
        "\n",
        "    splits_dir = os.path.join(mot_dir, \"splits_txt\")\n",
        "    football_sequences = load_football_sequences(splits_dir)\n",
        "\n",
        "    for seq in football_sequences:\n",
        "        seq_path = os.path.join(mot_dir, \"dataset\", split, seq)\n",
        "        gt_file = os.path.join(seq_path, \"gt\", \"gt.txt\")\n",
        "\n",
        "        if not os.path.exists(gt_file):\n",
        "            continue\n",
        "\n",
        "        df = pd.read_csv(gt_file, header=None)\n",
        "        df.columns = [\n",
        "            \"frame_id\", \"object_id\", \"x\", \"y\", \"w\", \"h\",\n",
        "            \"conf\", \"class_id\", \"visibility\"\n",
        "        ]\n",
        "\n",
        "        for frame_id, group in df.groupby(\"frame_id\"):\n",
        "            img_path = os.path.join(seq_path, \"img1\", f\"{frame_id:06d}.jpg\")\n",
        "            if not os.path.exists(img_path):\n",
        "                continue\n",
        "\n",
        "            img = cv2.imread(img_path)\n",
        "            img_name = f\"{seq}_{frame_id:06d}.jpg\"\n",
        "            cv2.imwrite(os.path.join(root_dir, \"dataset\", \"images\", split, img_name), img)\n",
        "\n",
        "            label_file = os.path.join(root_dir, \"dataset\", \"labels\", split, f\"{seq}_{frame_id:06d}.txt\")\n",
        "            with open(label_file, \"w\") as f:\n",
        "                for _, row in group.iterrows():\n",
        "                    x_center = (row[\"x\"] + row[\"w\"] / 2) / img.shape[1]\n",
        "                    y_center = (row[\"y\"] + row[\"h\"] / 2) / img.shape[0]\n",
        "                    width = row[\"w\"] / img.shape[1]\n",
        "                    height = row[\"h\"] / img.shape[0]\n",
        "                    f.write(f\"{int(row['class_id'])} {x_center} {y_center} {width} {height}\\n\")\n",
        "\n",
        "convert_to_yolo_format(\"/content\", \"/content/SportsMOT/sportsmot_publish\", \"train\")\n",
        "convert_to_yolo_format(\"/content\", \"/content/SportsMOT/sportsmot_publish\", \"val\")\n",
        "convert_to_yolo_format(\"/content\", \"/content/SportsMOT/sportsmot_publish\", \"test\")"
      ],
      "metadata": {
        "id": "O_yzqtrGXBzD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_yaml_file(dataset_dir, class_names):\n",
        "    yaml_content = f\"\"\"\n",
        "path: {dataset_dir}\n",
        "train: images/train\n",
        "val: images/val\n",
        "test: images/test\n",
        "\n",
        "nc: {len(class_names)}\n",
        "names: {class_names}\n",
        "\"\"\"\n",
        "    yaml_path = os.path.join(dataset_dir, \"dataset.yaml\")\n",
        "    with open(yaml_path, \"w\") as f:\n",
        "        f.write(yaml_content)\n",
        "\n",
        "    print(f\"YAML file created at: {yaml_path}\")\n",
        "\n",
        "dataset_dir = \"/content/dataset\"\n",
        "class_names = ['player', 'referee', 'ball', 'other']\n",
        "\n",
        "create_yaml_file(dataset_dir, class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pe32ad7kh4GI",
        "outputId": "fb887feb-f420-402e-d18d-8591c51487ec"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YAML file created at: /content/dataset/dataset.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "results = model.train(\n",
        "    data=\"/content/dataset/dataset.yaml\",\n",
        "    epochs=50,\n",
        "    imgsz=1280,\n",
        "    batch=16,\n",
        "    name=\"yolov8_football\",\n",
        "    verbose=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxSfOEkxbcRK",
        "outputId": "758b6b2f-6860-485a-a317-7fbd3a535a33"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 359MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.70 🚀 Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/dataset/dataset.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=720, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=yolov8_football, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/yolov8_football\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 98.9MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3,011,628 parameters, 3,011,612 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/yolov8_football', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 353MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "WARNING ⚠️ imgsz=[720] must be multiple of max stride 32, updating to [736]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/labels/train... 11113 images, 0 backgrounds, 0 corrupt: 100%|██████████| 11113/11113 [00:28<00:00, 390.40it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/dataset/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.2 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/labels/val... 9058 images, 0 backgrounds, 0 corrupt: 100%|██████████| 9058/9058 [00:11<00:00, 785.57it/s] "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000456.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000462.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000475.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000482.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000485.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000492.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000494.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000499.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000500.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000501.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000504.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000509.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000510.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000511.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000517.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000519.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000525.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000526.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000529.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000532.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000540.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000541.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000548.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000559.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000560.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000562.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000564.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000565.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000580.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000590.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000596.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000610.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000611.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000613.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000614.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000618.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000619.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000623.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000628.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000636.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000638.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000649.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000650.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000651.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000655.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000658.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000664.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000670.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000672.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000681.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000682.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000683.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000687.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000690.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000698.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000700.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000707.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000718.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000728.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000730.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000738.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000739.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000748.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000754.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000769.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000792.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000793.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000795.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000798.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000799.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000803.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000820.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000824.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000825.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000826.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000833.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000836.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000839.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000840.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000841.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000843.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000845.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000854.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000858.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000860.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000868.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000875.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000877.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000879.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000883.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/images/val/v_i2_L4qquVg0_c006_000887.jpg: 1 duplicate labels removed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/dataset/labels/val.cache\n",
            "Plotting labels to runs/detect/yolov8_football/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 736 train, 736 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/yolov8_football\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/50      3.34G     0.9294      0.851     0.8682        192        736: 100%|██████████| 695/695 [05:50<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 284/284 [02:08<00:00,  2.21it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       9058     117024        0.9      0.934      0.919        0.7\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/50      4.18G     0.8156     0.4863     0.8456        229        736: 100%|██████████| 695/695 [05:52<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 284/284 [02:07<00:00,  2.22it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       9058     117024       0.89       0.92      0.925      0.711\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/50      3.61G     0.7838      0.439     0.8382        235        736: 100%|██████████| 695/695 [05:57<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 284/284 [02:05<00:00,  2.26it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       9058     117024      0.902      0.939      0.935      0.747\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/50      3.26G     0.7628     0.4177     0.8349        174        736: 100%|██████████| 695/695 [05:49<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 284/284 [02:07<00:00,  2.24it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       9058     117024        0.9      0.938      0.934      0.742\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/50      3.92G     0.7382     0.3968     0.8309        246        736: 100%|██████████| 695/695 [05:46<00:00,  2.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 284/284 [02:06<00:00,  2.24it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       9058     117024      0.913      0.928      0.931      0.758\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/50      4.15G      0.724     0.3865     0.8286        173        736: 100%|██████████| 695/695 [05:46<00:00,  2.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 284/284 [02:04<00:00,  2.28it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       9058     117024      0.917      0.916      0.933      0.762\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/50      3.48G     0.7146     0.3779     0.8254        280        736: 100%|██████████| 695/695 [05:47<00:00,  2.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 284/284 [02:04<00:00,  2.29it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       9058     117024      0.932      0.919      0.952      0.775\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/50      3.69G     0.7007     0.3715     0.8242        167        736: 100%|██████████| 695/695 [05:46<00:00,  2.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 284/284 [02:02<00:00,  2.32it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       9058     117024      0.922      0.922      0.953      0.771\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/50      3.62G     0.6931     0.3627     0.8224        204        736: 100%|██████████| 695/695 [05:37<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 284/284 [02:03<00:00,  2.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       9058     117024      0.913      0.948       0.94      0.766\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/50      3.93G     0.6865     0.3578     0.8212        273        736: 100%|██████████| 695/695 [05:39<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 284/284 [02:03<00:00,  2.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       9058     117024      0.919      0.946      0.936      0.767\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/50      3.78G     0.6778     0.3524     0.8215        246        736: 100%|██████████| 695/695 [05:40<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 284/284 [02:01<00:00,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       9058     117024      0.924      0.941      0.941      0.774\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/50      4.37G     0.6713     0.3478     0.8193        251        736: 100%|██████████| 695/695 [05:38<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 284/284 [02:02<00:00,  2.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       9058     117024      0.913      0.929      0.932      0.765\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/50      3.79G     0.6614     0.3448     0.8187        187        736: 100%|██████████| 695/695 [05:33<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 284/284 [01:58<00:00,  2.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       9058     117024      0.923      0.943      0.945      0.779\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/50      3.94G     0.6599     0.3406     0.8178        199        736: 100%|██████████| 695/695 [05:33<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 284/284 [01:58<00:00,  2.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       9058     117024      0.918      0.944      0.936      0.773\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/50      3.94G     0.6577     0.3378     0.8176        136        736: 100%|██████████| 695/695 [05:23<00:00,  2.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 284/284 [01:55<00:00,  2.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       9058     117024      0.928      0.927       0.95      0.781\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/50      3.48G     0.6503     0.3336      0.817        180        736: 100%|██████████| 695/695 [05:21<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 284/284 [01:56<00:00,  2.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       9058     117024      0.925      0.938      0.944      0.785\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/50      3.75G     0.6451     0.3298     0.8153        300        736: 100%|██████████| 695/695 [05:18<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 284/284 [01:54<00:00,  2.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       9058     117024      0.929      0.946      0.945      0.789\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/50      3.51G     0.6391     0.3274     0.8144        255        736: 100%|██████████| 695/695 [05:25<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 284/284 [01:53<00:00,  2.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       9058     117024      0.929      0.934       0.94      0.785\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/50      3.87G     0.6384     0.3248     0.8157        219        736: 100%|██████████| 695/695 [05:22<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 284/284 [01:53<00:00,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       9058     117024      0.916      0.935      0.932      0.768\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/50      3.64G     0.6335     0.3213     0.8141        214        736: 100%|██████████| 695/695 [05:13<00:00,  2.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 284/284 [01:54<00:00,  2.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       9058     117024      0.924      0.934      0.942      0.787\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/50      3.54G     0.6304     0.3205     0.8139        181        736: 100%|██████████| 695/695 [05:18<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 284/284 [01:55<00:00,  2.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       9058     117024      0.926      0.934      0.939      0.781\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/50      3.96G     0.6256     0.3181     0.8132        149        736: 100%|██████████| 695/695 [05:19<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 284/284 [01:55<00:00,  2.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       9058     117024      0.922      0.932      0.935       0.78\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/50      3.62G     0.6235     0.3155     0.8121        232        736: 100%|██████████| 695/695 [05:24<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 284/284 [01:56<00:00,  2.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       9058     117024      0.924      0.937      0.937       0.78\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/50      3.77G     0.6193     0.3128     0.8125        189        736: 100%|██████████| 695/695 [05:21<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 284/284 [01:55<00:00,  2.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       9058     117024      0.929      0.934      0.942      0.783\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/50      3.66G     0.6172     0.3113     0.8118        182        736: 100%|██████████| 695/695 [05:22<00:00,  2.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 284/284 [01:57<00:00,  2.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       9058     117024      0.925      0.941      0.943      0.784\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/50      3.78G     0.6132     0.3094     0.8105        393        736:  36%|███▌      | 249/695 [01:51<03:00,  2.47it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_logs(results_path):\n",
        "    logs = pd.read_csv(results_path)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(logs[\"epoch\"], logs[\"train/box_loss\"], label=\"Train Box Loss\")\n",
        "    plt.plot(logs[\"epoch\"], logs[\"val/box_loss\"], label=\"Validation Box Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training and Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(logs[\"epoch\"], logs[\"metrics/mAP_0.5\"], label=\"mAP@0.5\")\n",
        "    plt.plot(logs[\"epoch\"], logs[\"metrics/mAP_0.5:0.95\"], label=\"mAP@0.5:0.95\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"mAP\")\n",
        "    plt.title(\"Mean Average Precision\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "results_path = \"/content/runs/detect/yolov8_football/results.csv\"\n",
        "plot_logs(results_path)"
      ],
      "metadata": {
        "id": "VPieolPiiJqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"/content/runs/detect/yolov8_football/weights/best.pt\")\n",
        "\n",
        "results = model(\"/content/dataset/images/test/seq101_000001.jpg\") # TODO\n",
        "\n",
        "for result in results:\n",
        "    result.show()\n",
        "    result.save(\"output.jpg\")"
      ],
      "metadata": {
        "id": "doBifmGaiMSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = model.val()\n",
        "\n",
        "print(f\"mAP@0.5: {metrics.box.map}\")\n",
        "print(f\"mAP@0.5:0.95: {metrics.box.map_50_95}\")"
      ],
      "metadata": {
        "id": "g3sbL4CqiPHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving to Hugging Face\n"
      ],
      "metadata": {
        "id": "gwRlxT9DO253"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "O3QyXLvYO7S-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/runs/detect/yolov8_football/weights/best.pt\"\n",
        "repo_id = \"ParsaGh/yolov8_football\"\n",
        "repo_name = \"yolov8_football\"\n",
        "\n",
        "model = YOLO(model_path)\n",
        "\n",
        "repo = Repository(l\n",
        "    ocal_dir=yolov8_football,\n",
        "    clone_from=repo_id,\n",
        "    use_auth_token=True\n",
        ")\n",
        "os.system(f\"cp {model_path} {repo_name}/\")\n",
        "repo.push_to_hub(commit_message=\"Upload YOLOv8-Football model\")"
      ],
      "metadata": {
        "id": "CRVnhYZIO-7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading From Hugging Face"
      ],
      "metadata": {
        "id": "nDBjsKSGQXd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = hf_hub_download(\n",
        "    repo_id=repo_id,\n",
        "    filename=\"best.pt\",\n",
        "    use_auth_token=True,\n",
        ")\n",
        "\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# results = model(\"path_to_test_image.jpg\") #TODO\n",
        "# results.show()"
      ],
      "metadata": {
        "id": "7fRqTtnmQb8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single Object Tracking"
      ],
      "metadata": {
        "id": "Jjg8E0uTkPd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SingleObjectTracker:\n",
        "    def __init__(self, yolo_weights='best.pt'):\n",
        "        self.yolo = YOLO(yolo_weights)\n",
        "        self.tracker = cv2.TrackerCSRT_create()\n",
        "        self.target_class = 0\n",
        "        self.last_valid_bbox = None\n",
        "        self.frames_since_last_detection = 0\n",
        "\n",
        "    def track(self, frame):\n",
        "        success, bbox = self.tracker.update(frame)\n",
        "\n",
        "        if not success or self._needs_reinitialization(bbox):\n",
        "            print(\"Attempting recovery...\")\n",
        "            success, bbox = self._reinitialize_tracker(frame)\n",
        "\n",
        "        if success:\n",
        "            self.last_valid_bbox = bbox\n",
        "            self.frames_since_last_detection = 0\n",
        "        else:\n",
        "            self.frames_since_last_detection += 1\n",
        "\n",
        "        return success, bbox\n",
        "\n",
        "    def _needs_reinitialization(self, bbox):\n",
        "        if bbox[2] <= 0 or bbox[3] <= 0:\n",
        "            return True\n",
        "        if self.last_valid_bbox:\n",
        "            # Check position change > 50% of frame size\n",
        "            dx = abs(bbox[0] - self.last_valid_bbox[0])/1280\n",
        "            dy = abs(bbox[1] - self.last_valid_bbox[1])/720\n",
        "            return dx > 0.5 or dy > 0.5\n",
        "        return False\n",
        "\n",
        "    def _reinitialize_tracker(self, frame):\n",
        "        # Search in last known position area\n",
        "        if self.last_valid_bbox:\n",
        "            x, y, w, h = self.last_valid_bbox\n",
        "            search_region = frame[int(y):int(y+h), int(x):int(x+w)]\n",
        "            results = self.yolo(search_region, verbose=False)[0]\n",
        "        else:\n",
        "            results = self.yolo(frame, verbose=False)[0]\n",
        "\n",
        "        # Filter and select best detection\n",
        "        athlete_boxes = []\n",
        "        for box, cls, conf in zip(results.boxes.xywh, results.boxes.cls, results.boxes.conf):\n",
        "            if cls == self.target_class and conf > 0.5:\n",
        "                athlete_boxes.append((conf, box.cpu().numpy()))\n",
        "\n",
        "        if athlete_boxes:\n",
        "            # Select closest to last position or highest confidence\n",
        "            best_conf, best_box = max(athlete_boxes, key=lambda x: x[0])\n",
        "            x_center, y_center, w, h = best_box\n",
        "            x = x_center - w/2 + (self.last_valid_bbox[0] if self.last_valid_bbox else 0)\n",
        "            y = y_center - h/2 + (self.last_valid_bbox[1] if self.last_valid_bbox else 0)\n",
        "            new_bbox = (x, y, w, h)\n",
        "            self.tracker = cv2.TrackerCSRT_create()\n",
        "            self.tracker.init(frame, new_bbox)\n",
        "            return True, new_bbox\n",
        "\n",
        "        return False, None\n",
        "\n",
        "def test_on_sportsmot_frames(data_dir, yolo_model, output_dir=\"results\"):\n",
        "    tracker = SingleObjectTracker(yolo_model)\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    frames_dir = os.path.join(data_dir, \"test\", \"images\")\n",
        "    frame_paths = sorted([os.path.join(frames_dir, f) for f in os.listdir(frames_dir)])\n",
        "\n",
        "    frame = cv2.imread(frame_paths[0])\n",
        "    if frame is None:\n",
        "        raise ValueError(\"No frames found in test directory\")\n",
        "\n",
        "    height, width = frame.shape[:2]\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(os.path.join(output_dir, 'tracking_results.mp4'),\n",
        "                         fourcc, 25.0, (width, height))\n",
        "\n",
        "    total_time = 0\n",
        "    first_frame = True\n",
        "\n",
        "    for frame_path in frame_paths:\n",
        "        frame = cv2.imread(frame_path)\n",
        "        if frame is None:\n",
        "            continue\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        if first_frame:\n",
        "            try:\n",
        "                bbox = tracker.initialize(frame)\n",
        "                first_frame = False\n",
        "                status = \"Initialized\"\n",
        "            except ValueError as e:\n",
        "                print(f\"Initialization failed: {e}\")\n",
        "                break\n",
        "        else:\n",
        "            success, bbox = tracker.track(frame)\n",
        "            status = \"Tracking\" if success else \"Lost\"\n",
        "\n",
        "        processing_time = time.time() - start_time\n",
        "        total_time += processing_time\n",
        "\n",
        "        if not first_frame and success:\n",
        "            x, y, w, h = [int(v) for v in bbox]\n",
        "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "\n",
        "        cv2.putText(frame, f\"Status: {status}\", (10, 30),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f\"FPS: {1/processing_time:.1f}\", (10, 70),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "        out.write(frame)\n",
        "\n",
        "    out.release()\n",
        "\n",
        "    avg_fps = len(frame_paths) / total_time\n",
        "    print(f\"Average FPS: {avg_fps:.1f}\")\n",
        "    print(f\"Results saved to: {os.path.abspath(output_dir)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example usage\n",
        "    sportsmot_test_dir = \"path/to/sportsmot_dataset/test\"  # Update this path\n",
        "    test_on_sportsmot_frames(sportsmot_test_dir)"
      ],
      "metadata": {
        "id": "d-onNQEpkXVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Uxrcq2ToU6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conditions Where CSRT Performs Well:\n",
        "\n",
        "\n",
        "Slow Motion: The object moves slowly relative to the frame rate.\n",
        "\n",
        "Minimal Occlusion: The object is not occluded by other objects.\n",
        "\n",
        "Consistent Lighting: The lighting conditions remain stable.\n",
        "\n",
        "Distinct Appearance: The object has a unique appearance compared to the background.\n",
        "\n",
        "### Conditions Where CSRT Performs Poorly:\n",
        "\n",
        "Fast Motion: The object moves quickly, causing the tracker to lose it.\n",
        "\n",
        "Occlusion: The object is occluded by other objects or goes out of the frame.\n",
        "\n",
        "Appearance Changes: The object's appearance changes significantly (e.g., due to lighting or deformation).\n",
        "\n",
        "Similar Background: The object blends into the background, making it hard to distinguish."
      ],
      "metadata": {
        "id": "LqM7jHF6oZNo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PC333TPhoaNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SFAunj08sdV4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}