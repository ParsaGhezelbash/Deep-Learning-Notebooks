{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch opencv-python pandas\n",
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d ayushspai/sportsmot\n",
    "!unzip sportsmot.zip -d SportsMOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xywh_to_x1y1x2y2(boxes):\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 0] + boxes[:, 2]\n",
    "    y2 = boxes[:, 1] + boxes[:, 3]\n",
    "\n",
    "    return torch.stack([x1, y1, x2, y2], dim=1)\n",
    "def filter_boxes(boxes, img_width=1280, img_height=720):\n",
    "    valid = (boxes[:, 0] >= 0) & \\\n",
    "            (boxes[:, 1] >= 0) & \\\n",
    "            (boxes[:, 0] + boxes[:, 2] <= img_width) & \\\n",
    "            (boxes[:, 1] + boxes[:, 3] <= img_height)\n",
    "    return boxes[valid]\n",
    "\n",
    "class BallEnhancer:\n",
    "    def __call__(self, image, boxes, classes):\n",
    "        ball_mask = (classes == 3)  # Assuming class 3 is ball\n",
    "        if ball_mask.any():\n",
    "            ball_img = self._enhance_ball(image, boxes[ball_mask])\n",
    "            image = cv2.addWeighted(image, 0.7, ball_img, 0.3, 0)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SportsMOTDataset(Dataset):\n",
    "    def __init__(self, root_dir, sequence=\"train/seq1\", transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): Root directory of dataset\n",
    "            sequence (str): Subdirectory path (e.g., \"train/seq1\")\n",
    "            transform (callable, optional): Optional transforms\n",
    "        \"\"\"\n",
    "        self.sequence_path = os.path.join(root_dir, sequence)\n",
    "        self.img_dir = os.path.join(self.sequence_path, \"img1\")\n",
    "        self.gt_file = os.path.join(self.sequence_path, \"gt\", \"gt.txt\")\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Load annotations\n",
    "        self.annotations = self._load_annotations()\n",
    "        self.frame_ids = sorted(list(self.annotations.keys()))\n",
    "        \n",
    "        # Default transforms\n",
    "        self.default_transform = Compose([\n",
    "            ToTensor(),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def _load_annotations(self):\n",
    "        \"\"\"Load annotations into {frame_id: list(annotations)} format\"\"\"\n",
    "        df = pd.read_csv(self.gt_file, header=None)\n",
    "        df.columns = [\n",
    "            \"frame_id\", \"object_id\", \"x\", \"y\", \"w\", \"h\",\n",
    "            \"conf\", \"class_id\", \"visibility\"\n",
    "        ]\n",
    "        \n",
    "        annotations = {}\n",
    "        for frame_id, group in df.groupby(\"frame_id\"):\n",
    "            annotations[frame_id] = {\n",
    "                \"boxes\": group[[\"x\", \"y\", \"w\", \"h\"]].values.astype(\"float32\"),\n",
    "                \"object_ids\": group[\"object_id\"].values.astype(\"int32\"),\n",
    "                \"classes\": group[\"class_id\"].values.astype(\"int32\")\n",
    "            }\n",
    "        return annotations\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frame_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        frame_id = self.frame_ids[idx]\n",
    "        img_path = os.path.join(self.img_dir, f\"{frame_id:06d}.jpg\")\n",
    "        \n",
    "        # Load image\n",
    "        image = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Get annotations\n",
    "        ann = self.annotations[frame_id]\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = self.default_transform(image)\n",
    "            \n",
    "        return image, {\n",
    "            \"boxes\": torch.tensor(ann[\"boxes\"]),\n",
    "            \"object_ids\": torch.tensor(ann[\"object_ids\"]),\n",
    "            \"classes\": torch.tensor(ann[\"classes\"]),\n",
    "            \"frame_id\": frame_id\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(root_dir, sequence, batch_size=4, shuffle=False):\n",
    "    dataset = SportsMOTDataset(\n",
    "        root_dir=root_dir,\n",
    "        sequence=sequence,\n",
    "        transform=Compose([\n",
    "            ToTensor(),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    )\n",
    "    \n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        collate_fn=custom_collate,\n",
    "        num_workers=4\n",
    "    )\n",
    "    return loader\n",
    "\n",
    "def custom_collate(batch):\n",
    "    \"\"\"Custom collate function to handle variable number of objects\"\"\"\n",
    "    images = torch.stack([item[0] for item in batch])\n",
    "    targets = [item[1] for item in batch]\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Initialize dataset\n",
    "    dataset = SportsMOTDataset(root_dir=\"/path/to/SportsMOT\", sequence=\"train/seq1\")\n",
    "    \n",
    "    # Create dataloader\n",
    "    dataloader = create_dataloader(\n",
    "        root_dir=\"/path/to/SportsMOT\",\n",
    "        sequence=\"train/seq1\",\n",
    "        batch_size=4,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Iterate through batches\n",
    "    for batch_idx, (images, targets) in enumerate(dataloader):\n",
    "        print(f\"Batch {batch_idx}:\")\n",
    "        print(f\"Images shape: {images.shape}\")\n",
    "        print(f\"Number of targets: {len(targets)}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        if batch_idx == 2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import RandomHorizontalFlip, ColorJitter\n",
    "\n",
    "train_transform = Compose([\n",
    "    ToTensor(),\n",
    "    RandomHorizontalFlip(p=0.5),\n",
    "    ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = SportsMOTDataset(\n",
    "    root_dir=\"/path/to/SportsMOT\",\n",
    "    sequence=\"train/seq1\",\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Split dataset\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=custom_collate)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample(image, boxes, object_ids):\n",
    "    \"\"\"Visualize a single frame with bounding boxes and object IDs\"\"\"\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(image.permute(1, 2, 0))  # Convert from (C, H, W) to (H, W, C)\n",
    "    \n",
    "    for box, obj_id in zip(boxes, object_ids):\n",
    "        x, y, w, h = box\n",
    "        rect = patches.Rectangle((x, y), w, h, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(x, y, f\"ID: {obj_id}\", color='r', fontsize=8, backgroundcolor='white')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Load a sample\n",
    "sample_image, sample_targets = dataset[0]\n",
    "visualize_sample(sample_image, sample_targets[\"boxes\"], sample_targets[\"object_ids\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
